{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xpAuMVCwfWs8"
   },
   "source": [
    "# Memory & Intelligence\n",
    "An important part of intelligence stems from memory. Memory -> contextual historic data that informs our predictive ability and actions in our day-day lives.  \n",
    "**NNs mimic our brains ability to remember through the preservation of the weights along the artificial synapses that link the neurons within the input, hidden and output layers of the NN.**\n",
    "**The weights are the long-term memory of the ANN.**\n",
    "# Recurrent Neural Networks\n",
    "### RNNs (their weights) mimic the short-term memory of the brain.\n",
    "An RNN is a **squashed & twisted** ANN that has a feedabck loop which generates the short-term memory.\n",
    "![](images/rnn1.jpg)\n",
    "![](images/rnn2.jpg)\n",
    "![](images/rnn3.jpg)\n",
    "![](images/rnn4.jpg)\n",
    "![](images/rnn5.jpg)\n",
    "### The hidden layers know the prior state of the adjacent hidden layer which creates this \"short-term memory\" feature that RNNs have.\n",
    "![](images/rnn6.jpg)\n",
    "#### Now if we extrapolate over multiple layers, we get...............\n",
    "![](images/rnn7.jpg)\n",
    "### The power of RNNs is unleashed when they are combined with other NNs such as CNNs and NLP models. This short term memory feature gets transfered to whatever task (visual or text-based) that it is being applied towards.\n",
    "### Examples of the the uses of RNNs based on their structure\n",
    "![](images/rnn8.jpg)\n",
    "1. Top right - contextual image labelling.\n",
    "2. Top left - chatbots that can keep a conversation going.\n",
    "3. Bottom right - language translations.\n",
    "4. Bottom left - real-time video contextual labelling -> Self driving cars.\n",
    "## The Vanishing Gradient Problem of RNNs.\n",
    "![](images/rnn10.jpg)\n",
    "After feed-forward action, the cost function generates the error and now we want to back-propagate this weight adjustment through the the RNN inorder to improve the RNNs accuracy.  \n",
    "![](images/rnn11.jpg)\n",
    "Essentially, the weight adjustment process , involves multiplying the previous weights by `Wrec`.  \n",
    "**The problem comes if `Wrec` is a small number (<<<1). This will result in weights that become very small numbers after the multplication (weight adjustment process) which negatively affects the back-propagation process usign gradient descent because the gradients also continually decrease and....vanish. The lower the gradient is ,the more slower the weights are updated  and ultimately the each prior neuron is being trained less and less which leads to an imbalance in weight training across the entire RNN.**   \n",
    "\n",
    "\n",
    "**If `Wrec` is too large (>>>1) then we have `exploding` gradients which is another problem all together.**\n",
    "![](images/rnn12.jpg)\n",
    "\n",
    "### Dealing with `Vanishing` & `Exploding` gradients\n",
    "![](images/rnn13.jpg)\n",
    "# Long Short-Term Memory Networks (LSTMs)\n",
    "### Academic LSTM Illustration\n",
    "![](images/lstm2.jpg)\n",
    "## How did the LSTM improve the RNN ?\n",
    "### Standard RNN\n",
    "![](images/rnninside.jpg)\n",
    "### LSTM\n",
    "![](images/lstm1.jpg)  \n",
    "\n",
    "### LSTMs have a `memory cell` `C(t-1) -> C(t)` that flows through 'time' freely allowing for a more robust backpropagation.\n",
    "![](images/lstm4.jpg)\n",
    "## The pracitcal workings of LSTMs\n",
    "![](images/lstm5.jpg)\n",
    "### Examples\n",
    "![](images/lstm6.jpg)\n",
    "![](images/lstm7.jpg)\n",
    "## LSTM architectural variations\n",
    "### Standard LSTM\n",
    "![](images/lstm8.jpg)\n",
    "### LSTM with peep-holes\n",
    "![](images/lstm9.jpg)\n",
    "### LSTM with combined `memory` and `forget` valves\n",
    "![](images/lstm10.jpg)\n",
    "### Gated Recurrent Network - eliminates the memory cell.\n",
    "![](images/lstm11.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Objective\n",
    "### Predicting the stock price trends of Google/Alphabet  in 2017 using historical stock price data.\n",
    "### I will focus on only the `opening price` trends.\n",
    "### Regression problem.\n",
    "## Data\n",
    "Training data - Google stock price from 2012 - 2016.  \n",
    "Test data - Google stock price in January 2017.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nxJfRe4bfYVA"
   },
   "source": [
    "## Part 1 - Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ir9zwETrfbrp"
   },
   "source": [
    "### Importing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "ZT1f24vHffuf"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nQ47JAxrgmaL"
   },
   "source": [
    "### Importing the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1/3/2012</td>\n",
       "      <td>325.25</td>\n",
       "      <td>332.83</td>\n",
       "      <td>324.97</td>\n",
       "      <td>663.59</td>\n",
       "      <td>7,380,500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1/4/2012</td>\n",
       "      <td>331.27</td>\n",
       "      <td>333.87</td>\n",
       "      <td>329.08</td>\n",
       "      <td>666.45</td>\n",
       "      <td>5,749,400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1/5/2012</td>\n",
       "      <td>329.83</td>\n",
       "      <td>330.75</td>\n",
       "      <td>326.89</td>\n",
       "      <td>657.21</td>\n",
       "      <td>6,590,300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1/6/2012</td>\n",
       "      <td>328.34</td>\n",
       "      <td>328.77</td>\n",
       "      <td>323.68</td>\n",
       "      <td>648.24</td>\n",
       "      <td>5,405,900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1/9/2012</td>\n",
       "      <td>322.04</td>\n",
       "      <td>322.29</td>\n",
       "      <td>309.46</td>\n",
       "      <td>620.76</td>\n",
       "      <td>11,688,800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Date    Open    High     Low   Close      Volume\n",
       "0  1/3/2012  325.25  332.83  324.97  663.59   7,380,500\n",
       "1  1/4/2012  331.27  333.87  329.08  666.45   5,749,400\n",
       "2  1/5/2012  329.83  330.75  326.89  657.21   6,590,300\n",
       "3  1/6/2012  328.34  328.77  323.68  648.24   5,405,900\n",
       "4  1/9/2012  322.04  322.29  309.46  620.76  11,688,800"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = pd.read_csv('data/Google_Stock_Price_Train.csv')\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[325.25],\n",
       "       [331.27],\n",
       "       [329.83],\n",
       "       [328.34],\n",
       "       [322.04]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set = train_data.iloc[:, 1:2].values\n",
    "training_set[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HT8_2UJegtG5"
   },
   "source": [
    "### Feature Scaling\n",
    "Here I **normalized** the data because it is advisable to do so when working with LSTMs since they utilize the 'sigmoid' activation function on the output layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "sc = MinMaxScaler(feature_range = (0, 1))\n",
    "training_set_scaled = sc.fit_transform(training_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.08581368],\n",
       "       [0.09701243],\n",
       "       [0.09433366],\n",
       "       [0.09156187],\n",
       "       [0.07984225]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set_scaled[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1258"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(training_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JyYgYocqhNUg"
   },
   "source": [
    "### Creating a data structure with 60 timesteps and 1 output\n",
    "Correct timestep number prevents overfitting.  \n",
    "**In this case, a 60 timestep means that a time (t) the LSTM will look at the opening stock prices 60 days before time (t), learn from the trends in the stock price data and use that to predict the stock price at time (t+1).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = []\n",
    "y_train = []\n",
    "\n",
    "for i in range(60, len(training_set)):\n",
    "    X_train.append(training_set_scaled[i-60:i,0])\n",
    "    y_train.append(training_set_scaled[i,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = np.array(X_train) , np.array(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eack X_train list entry contains 60 opening stock prices (t-60:t-1) and the corresponding y_train entry list will contain the opening stock price at time (t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.08581368, 0.09701243, 0.09433366, ..., 0.07846566, 0.08034452,\n",
       "        0.08497656],\n",
       "       [0.09701243, 0.09433366, 0.09156187, ..., 0.08034452, 0.08497656,\n",
       "        0.08627874],\n",
       "       [0.09433366, 0.09156187, 0.07984225, ..., 0.08497656, 0.08627874,\n",
       "        0.08471612],\n",
       "       ...,\n",
       "       [0.92106928, 0.92438053, 0.93048218, ..., 0.95475854, 0.95204256,\n",
       "        0.95163331],\n",
       "       [0.92438053, 0.93048218, 0.9299055 , ..., 0.95204256, 0.95163331,\n",
       "        0.95725128],\n",
       "       [0.93048218, 0.9299055 , 0.93113327, ..., 0.95163331, 0.95725128,\n",
       "        0.93796041]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.08627874, 0.08471612, 0.07454052, ..., 0.95725128, 0.93796041,\n",
       "       0.93688146])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1198, 1198)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train), len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1198, 60)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reshaping\n",
    "Adding the `unit` - the number of predictors we can use to predict the opening stock price.  \n",
    "This will add an additional dimension to the training data to make it compatible with the LSTM input layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))\n",
    "# This np.array shape is now (#stock prices, #timesteps, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1198, 60, 1)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZRRSOJeVjEWV"
   },
   "source": [
    "## Part 2 - Building and Training the Stacked RNN (LSTM) Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k4XV88JMjHXG"
   },
   "source": [
    "### Importing the Keras libraries and packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FEIE-1s9jNzC"
   },
   "source": [
    "### Initialising the RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "62eg1OPGjT8z"
   },
   "source": [
    "### Adding the first LSTM layer and some Dropout regularisation\n",
    "We add dropout regularisation to prevent overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM layer\n",
    "rnn.add(LSTM(units = 50, # We want many neurons (higher dimensionality of NN) to capture the complexity of stock price data\n",
    "             return_sequences = True, # To enable us to add/stack another LSTM layer\n",
    "             input_shape = (X_train.shape[1], 1))) # Will be (#timesteps, #indicators)\n",
    "\n",
    "# Dropout Layer\n",
    "rnn.add(Dropout(0.2)) # 20% dropout - 20% of neurons will be ignored during training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3XBIYLyOjlMx"
   },
   "source": [
    "### Adding a second LSTM layer and some Dropout regularisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn.add(LSTM(units = 50, return_sequences = True))\n",
    "rnn.add(Dropout(0.2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ey3fHVnGj1cu"
   },
   "source": [
    "### Adding a third LSTM layer and some Dropout regularisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn.add(LSTM(units = 50, return_sequences = True))\n",
    "rnn.add(Dropout(0.2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SYTrtfTmj933"
   },
   "source": [
    "### Adding a fourth and final LSTM layer and some Dropout regularisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn.add(LSTM(units = 50, return_sequences = False))\n",
    "rnn.add(Dropout(0.2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9ABI6rOIkHhk"
   },
   "source": [
    "### Adding the fully connected output layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn.add(Dense(units = 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zLx4K7uUkPSh"
   },
   "source": [
    "### Compiling the RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn.compile(optimizer = 'adam',\n",
    "           loss = 'mean_squared_error') # Since this is a regression problem ( continuous value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-mPhwKGkkebi"
   },
   "source": [
    "### Fitting the RNN to the Training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "38/38 [==============================] - 12s 106ms/step - loss: 0.1021\n",
      "Epoch 2/100\n",
      "38/38 [==============================] - 4s 114ms/step - loss: 0.0067\n",
      "Epoch 3/100\n",
      "38/38 [==============================] - 4s 103ms/step - loss: 0.0056\n",
      "Epoch 4/100\n",
      "38/38 [==============================] - 4s 100ms/step - loss: 0.0053\n",
      "Epoch 5/100\n",
      "38/38 [==============================] - 4s 105ms/step - loss: 0.0047\n",
      "Epoch 6/100\n",
      "38/38 [==============================] - 4s 101ms/step - loss: 0.0048\n",
      "Epoch 7/100\n",
      "38/38 [==============================] - 4s 103ms/step - loss: 0.0051\n",
      "Epoch 8/100\n",
      "38/38 [==============================] - 4s 104ms/step - loss: 0.0042\n",
      "Epoch 9/100\n",
      "38/38 [==============================] - 4s 102ms/step - loss: 0.0045\n",
      "Epoch 10/100\n",
      "38/38 [==============================] - 4s 115ms/step - loss: 0.0043\n",
      "Epoch 11/100\n",
      "38/38 [==============================] - 4s 114ms/step - loss: 0.0038\n",
      "Epoch 12/100\n",
      "38/38 [==============================] - 4s 115ms/step - loss: 0.0037\n",
      "Epoch 13/100\n",
      "38/38 [==============================] - 4s 114ms/step - loss: 0.0034\n",
      "Epoch 14/100\n",
      "38/38 [==============================] - 4s 113ms/step - loss: 0.0043\n",
      "Epoch 15/100\n",
      "38/38 [==============================] - 4s 110ms/step - loss: 0.0051\n",
      "Epoch 16/100\n",
      "38/38 [==============================] - 4s 106ms/step - loss: 0.0040\n",
      "Epoch 17/100\n",
      "38/38 [==============================] - 4s 117ms/step - loss: 0.0040\n",
      "Epoch 18/100\n",
      "38/38 [==============================] - 4s 109ms/step - loss: 0.0037\n",
      "Epoch 19/100\n",
      "38/38 [==============================] - 4s 110ms/step - loss: 0.0033\n",
      "Epoch 20/100\n",
      "38/38 [==============================] - 4s 107ms/step - loss: 0.0038\n",
      "Epoch 21/100\n",
      "38/38 [==============================] - 4s 115ms/step - loss: 0.0034\n",
      "Epoch 22/100\n",
      "38/38 [==============================] - 4s 96ms/step - loss: 0.0042\n",
      "Epoch 23/100\n",
      "38/38 [==============================] - 4s 99ms/step - loss: 0.0034\n",
      "Epoch 24/100\n",
      "38/38 [==============================] - 4s 103ms/step - loss: 0.0029\n",
      "Epoch 25/100\n",
      "38/38 [==============================] - 5s 118ms/step - loss: 0.0035\n",
      "Epoch 26/100\n",
      "38/38 [==============================] - 4s 111ms/step - loss: 0.0039\n",
      "Epoch 27/100\n",
      "38/38 [==============================] - 4s 117ms/step - loss: 0.0031\n",
      "Epoch 28/100\n",
      "38/38 [==============================] - 5s 122ms/step - loss: 0.0029\n",
      "Epoch 29/100\n",
      "38/38 [==============================] - 5s 127ms/step - loss: 0.0029\n",
      "Epoch 30/100\n",
      "38/38 [==============================] - 5s 126ms/step - loss: 0.0028\n",
      "Epoch 31/100\n",
      "38/38 [==============================] - 6s 154ms/step - loss: 0.0035\n",
      "Epoch 32/100\n",
      "38/38 [==============================] - 6s 148ms/step - loss: 0.0032\n",
      "Epoch 33/100\n",
      "38/38 [==============================] - 6s 170ms/step - loss: 0.0035\n",
      "Epoch 34/100\n",
      "38/38 [==============================] - 6s 160ms/step - loss: 0.0031\n",
      "Epoch 35/100\n",
      "38/38 [==============================] - 7s 194ms/step - loss: 0.0025\n",
      "Epoch 36/100\n",
      "38/38 [==============================] - 6s 168ms/step - loss: 0.0028 1s - lo\n",
      "Epoch 37/100\n",
      "38/38 [==============================] - 6s 158ms/step - loss: 0.0028\n",
      "Epoch 38/100\n",
      "38/38 [==============================] - 9s 227ms/step - loss: 0.0025\n",
      "Epoch 39/100\n",
      "38/38 [==============================] - 7s 173ms/step - loss: 0.0027\n",
      "Epoch 40/100\n",
      "38/38 [==============================] - 8s 207ms/step - loss: 0.0031\n",
      "Epoch 41/100\n",
      "38/38 [==============================] - 7s 194ms/step - loss: 0.0025\n",
      "Epoch 42/100\n",
      "38/38 [==============================] - 7s 196ms/step - loss: 0.0028\n",
      "Epoch 43/100\n",
      "38/38 [==============================] - 7s 185ms/step - loss: 0.0031\n",
      "Epoch 44/100\n",
      "38/38 [==============================] - 8s 199ms/step - loss: 0.0024\n",
      "Epoch 45/100\n",
      "38/38 [==============================] - 7s 175ms/step - loss: 0.0026\n",
      "Epoch 46/100\n",
      "38/38 [==============================] - 6s 146ms/step - loss: 0.0027\n",
      "Epoch 47/100\n",
      "38/38 [==============================] - 5s 141ms/step - loss: 0.0024\n",
      "Epoch 48/100\n",
      "38/38 [==============================] - 5s 136ms/step - loss: 0.0027\n",
      "Epoch 49/100\n",
      "38/38 [==============================] - 6s 146ms/step - loss: 0.0021\n",
      "Epoch 50/100\n",
      "38/38 [==============================] - 5s 137ms/step - loss: 0.0020\n",
      "Epoch 51/100\n",
      "38/38 [==============================] - 5s 136ms/step - loss: 0.0024\n",
      "Epoch 52/100\n",
      "38/38 [==============================] - 5s 134ms/step - loss: 0.0021\n",
      "Epoch 53/100\n",
      "38/38 [==============================] - 5s 133ms/step - loss: 0.0023\n",
      "Epoch 54/100\n",
      "38/38 [==============================] - 5s 137ms/step - loss: 0.0026\n",
      "Epoch 55/100\n",
      "38/38 [==============================] - 5s 133ms/step - loss: 0.0019\n",
      "Epoch 56/100\n",
      "38/38 [==============================] - 5s 126ms/step - loss: 0.0021\n",
      "Epoch 57/100\n",
      "38/38 [==============================] - 5s 133ms/step - loss: 0.0022\n",
      "Epoch 58/100\n",
      "38/38 [==============================] - 5s 143ms/step - loss: 0.0024\n",
      "Epoch 59/100\n",
      "38/38 [==============================] - 6s 147ms/step - loss: 0.0020\n",
      "Epoch 60/100\n",
      "38/38 [==============================] - 5s 142ms/step - loss: 0.0021\n",
      "Epoch 61/100\n",
      "38/38 [==============================] - 5s 132ms/step - loss: 0.0022\n",
      "Epoch 62/100\n",
      "38/38 [==============================] - 5s 127ms/step - loss: 0.0024\n",
      "Epoch 63/100\n",
      "38/38 [==============================] - 5s 123ms/step - loss: 0.0021\n",
      "Epoch 64/100\n",
      "38/38 [==============================] - 5s 124ms/step - loss: 0.0022\n",
      "Epoch 65/100\n",
      "38/38 [==============================] - 5s 127ms/step - loss: 0.0019\n",
      "Epoch 66/100\n",
      "38/38 [==============================] - 5s 125ms/step - loss: 0.0020\n",
      "Epoch 67/100\n",
      "38/38 [==============================] - 5s 128ms/step - loss: 0.0019\n",
      "Epoch 68/100\n",
      "38/38 [==============================] - 5s 123ms/step - loss: 0.0022\n",
      "Epoch 69/100\n",
      "38/38 [==============================] - 5s 123ms/step - loss: 0.0019\n",
      "Epoch 70/100\n",
      "38/38 [==============================] - 5s 125ms/step - loss: 0.0018\n",
      "Epoch 71/100\n",
      "38/38 [==============================] - 5s 119ms/step - loss: 0.0019\n",
      "Epoch 72/100\n",
      "38/38 [==============================] - 5s 123ms/step - loss: 0.0018\n",
      "Epoch 73/100\n",
      "38/38 [==============================] - 5s 118ms/step - loss: 0.0019\n",
      "Epoch 74/100\n",
      "38/38 [==============================] - 5s 133ms/step - loss: 0.0017\n",
      "Epoch 75/100\n",
      "38/38 [==============================] - 5s 121ms/step - loss: 0.0018\n",
      "Epoch 76/100\n",
      "38/38 [==============================] - 4s 117ms/step - loss: 0.0019\n",
      "Epoch 77/100\n",
      "38/38 [==============================] - 4s 117ms/step - loss: 0.0019\n",
      "Epoch 78/100\n",
      "38/38 [==============================] - 5s 122ms/step - loss: 0.0018\n",
      "Epoch 79/100\n",
      "38/38 [==============================] - 5s 124ms/step - loss: 0.0016\n",
      "Epoch 80/100\n",
      "38/38 [==============================] - 5s 135ms/step - loss: 0.0018\n",
      "Epoch 81/100\n",
      "38/38 [==============================] - 5s 138ms/step - loss: 0.0017\n",
      "Epoch 82/100\n",
      "38/38 [==============================] - 5s 134ms/step - loss: 0.0019\n",
      "Epoch 83/100\n",
      "38/38 [==============================] - 5s 120ms/step - loss: 0.0019\n",
      "Epoch 84/100\n",
      "38/38 [==============================] - 4s 116ms/step - loss: 0.0015\n",
      "Epoch 85/100\n",
      "38/38 [==============================] - 5s 120ms/step - loss: 0.0017\n",
      "Epoch 86/100\n",
      "38/38 [==============================] - 5s 121ms/step - loss: 0.0017\n",
      "Epoch 87/100\n",
      "38/38 [==============================] - 4s 114ms/step - loss: 0.0017\n",
      "Epoch 88/100\n",
      "38/38 [==============================] - 5s 121ms/step - loss: 0.0015\n",
      "Epoch 89/100\n",
      "38/38 [==============================] - 5s 119ms/step - loss: 0.0016\n",
      "Epoch 90/100\n",
      "38/38 [==============================] - 5s 119ms/step - loss: 0.0014\n",
      "Epoch 91/100\n",
      "38/38 [==============================] - 5s 122ms/step - loss: 0.0015\n",
      "Epoch 92/100\n",
      "38/38 [==============================] - 5s 125ms/step - loss: 0.0017\n",
      "Epoch 93/100\n",
      "38/38 [==============================] - 4s 115ms/step - loss: 0.0012\n",
      "Epoch 94/100\n",
      "38/38 [==============================] - 4s 117ms/step - loss: 0.0014\n",
      "Epoch 95/100\n",
      "38/38 [==============================] - 5s 124ms/step - loss: 0.0016\n",
      "Epoch 96/100\n",
      "38/38 [==============================] - 5s 142ms/step - loss: 0.0015\n",
      "Epoch 97/100\n",
      "38/38 [==============================] - 5s 130ms/step - loss: 0.0015\n",
      "Epoch 98/100\n",
      "38/38 [==============================] - 5s 119ms/step - loss: 0.0015\n",
      "Epoch 99/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/38 [==============================] - 5s 119ms/step - loss: 0.0015\n",
      "Epoch 100/100\n",
      "38/38 [==============================] - 4s 117ms/step - loss: 0.0013\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fb111d20d60>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn.fit(X_train, y_train, epochs = 100, batch_size = 32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4hRau_lIkrE8"
   },
   "source": [
    "## Part 3 - Making the predictions and visualising the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SgJO6qEDksxD"
   },
   "source": [
    "### Getting the real stock prices of 2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv('data/Google_Stock_Price_Test.csv')\n",
    "true_stock_prices = test_data.iloc[:, 1:2].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GrvrLblxkz42"
   },
   "source": [
    "### Getting the RNN-predicted stock prices of 2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    325.25\n",
       "1    331.27\n",
       "2    329.83\n",
       "3    328.34\n",
       "4    322.04\n",
       "Name: Open, dtype: float64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Concatenating the train_data and test_data\n",
    "all_data = pd.concat((train_data.Open, test_data.Open), axis=0)\n",
    "all_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the inputs - From the 2017 data -  At each time (t) we need the previous 60 stock prices \n",
    "inputs = all_data[(len(all_data) - len(test_data))-60:].values\n",
    "inputs = inputs.reshape(-1,1)\n",
    "\n",
    "# Scaling the inputs\n",
    "inputs = sc.transform(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(true_stock_prices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshaping the inputs just like X_train\n",
    "X_test = []\n",
    "\n",
    "for i in range(60, 60+len(true_stock_prices)):\n",
    "    X_test.append(inputs[i-60:i,0])\n",
    "\n",
    "X_test = np.array(X_test)\n",
    "\n",
    "X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))\n",
    "# This np.array shape is now (#stock prices, #timesteps, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making predictions using X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_stock_prices = rnn.predict(X_test)\n",
    "\n",
    "# Inverse transforming the predictions\n",
    "predicted_stock_prices = sc.inverse_transform(predicted_stock_prices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iFTNs3YHk6FQ"
   },
   "source": [
    "### Visualising the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(true_stock_prices, color = 'red', label = 'Truth')\n",
    "plt.plot(predicted_stock_prices, color = 'blue', label = 'Prediction')\n",
    "plt.title('Google Stock Price Prediction for January 2017')\n",
    "plt.xlabel('Time')\n",
    "plt.legend()\n",
    "plt.ylabel('Opening Stock Price')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4 - Evaluating the RNN using RMSE (Root Mean Squared Error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The RNNs RMSE is:  11.939283094427015\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "rmse = np.sqrt(mean_squared_error(true_stock_prices, predicted_stock_prices))\n",
    "print(\"The RNNs RMSE is: \", rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### An RMSE of around 12 for opening stock prices ranging from 778 - 837 indicates realiable and accurate stock price predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How can I improve this RNN (LSTM) Model in the future ? \n",
    "1. **Getting more training data**: I trained the RNN model on the past 5 years of the Google Stock Price but it would be even better to train it on the past 10 years.\n",
    "2. **Increasing the number of timesteps**: the model remembered the stock prices from the 60 previous financial days to predict the stock price of the next day. Thats because I chose a number of 60 timesteps (3 months). I could try to increase the number of timesteps, by choosing for example 120 timesteps (6 months).\n",
    "3. **Adding some other indicators**: if you have the financial instinct that the stock price of some other companies might be correlated to the one of Google, you could add this other stock price as a new indicator in the training data.\n",
    "4. **Adding more LSTM layer**s: I built a RNN with four LSTM layers but it would be wise to try with even more.\n",
    "5. **Adding more neurones in the LSTM layers**: I would try an architecture with even more neurones in each of the 4 (or more) LSTM layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "rnn.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
